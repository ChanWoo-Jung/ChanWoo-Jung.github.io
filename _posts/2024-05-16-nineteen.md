---
layout: single
title: "RAG(Retrieval Augmented Generation)은 무엇인가?"
categories: AI
---


# RAG(검색 증강 생성)란? – LLM 단점을 보완하는 기술

LLM(Large Language Model)의 많은 장점에도 불구하고 단점을 보완하기 위한 RAG(검색 증강 생성)이 많은 관심을 받고 있습니다. RAG의 기본 개념, 등장 배경, 원리, 적용 사례 등을 알아보겠습니다.



## LLM이란?

LLM은 Large Language Model의 약자로, 자연어 처리(NLP)에서 사용되는 인공지능 기술의 한 종류이다. 이 모델들은 [대규모의 텍스트 데이터] (대규모의 데이타셋)를 학습하여 언어의 구조와 의미를 이해하고, 그 학습을 바탕으로 텍스트 생성, 번역, 요약, 질문에 대한 답변 등 다양한 언어 관련 작업을 할 수 있습니다.

*LLM의 주요 특징은 다음과 같습니다.*

- 방대한 지식 보유: 다양한 분야의 텍스트를 학습하여 광범위한 지식을 갖추고 있다.
- 문맥 이해 능력: 단순히 단어를 매칭하는 것이 아니라 전후 맥락을 고려하여 언어를 이해할 수 있다.
- 자연어 생성 능력: 문장 생성, 질문 응답, 요약, 번역 등 다양한 자연어 처리 태스크를 수행할 수 있다.
- 전이 학습 능력: 한 분야에서 학습한 지식을 다른 유사 태스크에 활용하는 등 전이 학습이 가능.
- 확장성: 더 많은 데이터와 컴퓨팅 자원을 활용하면서 지속적 성능 향상.

LLM은 챗봇, 검색 엔진, 콘텐츠 생성 등 다양한 분야에서 활용되고 있으며, 인간과 유사한 수준의 언어 이해와 생성 능력을 보여주고 있지만 편향성 문제, 사실 관계 오류 등의 한계점도 지적되고 있어 해결해야 할 과제도 남아있는 상황이다.



## LLM의 단점

_LLM(Large Language Model)은 많은 장점에도 불구하고 다음과 같은 단점과 한계점을 있다._

1. 편향성 문제
   - 학습 데이터에 내재된 편향성을 그대로 반영할 수 있음
   - 성별, 인종, 종교 등에 대한 고정관념이나 차별적 표현을 생성할 위험 존재
2. 사실 관계 오류 가능성
   - 방대한 데이터를 학습하지만, 항상 정확한 정보를 제공하지는 않음
   - 잘못된 정보나 허위 정보를 진실로 간주하고 전파할 수 있음
3. 맥락 이해의 한계
   - 문장 단위의 이해는 가능하지만, 장문의 글이나 복잡한 맥락 파악은 어려울 수 있음
   - 세계 지식과 상식 추론 능력이 부족하여 심층적인 이해에 한계 존재
4. 일관성 문제
   - 동일한 입력에 대해 일관된 답변을 생성하지 않을 수 있음
   - 모델의 확률적 특성상 생성 결과가 매번 달라질 수 있어 신뢰성 저하
5. 윤리적 문제
   - 악용 가능성이 존재하며, 책임 소재 파악이 어려울 수 있음
   - 모델의 출력 결과에 대한 통제와 검증 체계 마련 필요



## RAG는 LLM의 단점 중 무엇을 개선하는가?

RAG(Retrieval-Augmented Generation)는 LLM의 단점 중 ‘사실 관계 오류 가능성’과 ‘맥락 이해의 한계’를 개선하는 데 초점을 맞춘 방법이다.

 RAG는 LLM에 외부 지식 베이스를 연결하여 모델의 생성 능력과 사실 관계 파악 능력을 향상시키는 기술임  구체적으로 RAG는 다음과 같은 방식으로 LLM의 한계를 보완한다.

1. 외부 지식 활용

   - 대규모의 구조화된 지식 베이스(예: 위키피디아)를 모델에 연결
   - 주어진 질의에 대한 관련 정보를 지식 베이스에서 검색 및 추출

2. 증거 기반 생성

   - 검색된 지식 정보를 증거로 활용하여 보다 사실에 기반한 답변 생성
   - 생성된 답변의 출처를 명시함으로써 신뢰성 향상

3. 맥락 이해력 향상

   - 외부 지식을 통해 질의에 대한 배경 지식과 맥락 정보를 파악

   - 단순한 패턴 매칭이 아닌 추론 능력을 바탕으로 한 답변 생성

     

 RAG는 기존 LLM의 생성 능력에 외부 지식 베이스의 정보를 결합함으로써, 보다 정확하고 사실에 기반한 답변을 제공할 수 있으며,  또한 모델의 출력 결과에 대한 증거를 제시할 수 있어 설명 가능성과 신뢰성을 높일 수 있다.



## RAG의 기본 개념

RAG(Retrieval-Augmented Generation)는 대규모 언어 모델(LLM)의 한계를 극복하기 위해 제안된 새로운 자연어 처리 기술.  

LLM은 방대한 양의 텍스트 데이터를 사전 학습하여 강력한 언어 이해 및 생성 능력을 갖추고 있지만, 학습 데이터에 없는 최신 정보나 특정 도메인 지식은 제공하기 어렵다는 단점.

RAG는 이러한 LLM의 한계를 극복하기 위해 ‘지식 검색, 특정도메인 검색’ 과 ‘언어 생성’을 결합한 프레임워크.

RAG의 기본 아이디어는 질문에 정확하고 신뢰성있는 답을 구하기 위해  필요한 지식을 외부 데이터베이스에서 검색하여 활용하는 것



### RAG의 주요 구성 요소

1. 질의 인코더(Query Encoder): 사용자의 질문을 이해하기 위한 언어 모델입니다. 주어진 질문을 벡터 형태로 인코딩합니다.
2. 지식 검색기(Knowledge Retriever): 인코딩된 질문을 바탕으로 외부 지식 베이스에서 관련 정보를 검색합니다. 예를 들어 Wikipedia, 뉴스 기사, 전문 서적 등 방대한 문서 집합에서 질문과 연관된 문단이나 구절을 찾아냅니다.
3. 지식 증강 생성기(Knowledge-Augmented Generator): 검색된 지식을 활용하여 질문에 대한 답변을 생성하는 언어 모델입니다. 기존의 LLM과 유사하지만, 검색된 지식을 추가 입력으로 받아 보다 정확하고 풍부한 답변을 생성할 수 있습니다.



### RAG의 동작 과정 요약

1. 사용자의 질문이 주어지면 질의 인코더가 이를 이해하기 쉬운 형태로 변환합니다.
2. 지식 검색기가 인코딩된 질문을 바탕으로 외부 지식 베이스에서 관련 정보를 검색합니다.
3. 검색된 지식은 지식 증강 생성기의 입력으로 전달됩니다.
4. 지식 증강 생성기는 검색된 지식을 활용하여 사용자 질문에 대한 답변을 생성합니다.

RAG는 LLM의 강력한 언어 이해 및 생성 능력과 외부 지식 활용을 결합함으로써, 보다 정확하고 풍부한 정보를 제공할 수 있습니다. 특히 최신 정보나 특정 도메인 지식이 필요한 질문에 효과적으로 대응할 수 있다는 장점이 있습니다.



## RAG의 등장 배경과 필요성

RAG는 자연어 처리와 인공지능 기술의 발전, 그리고 증가하는 사용자의 요구에 따라 등장하게 되었습니다. RAG의 등장 배경과 필요성을 다음과 같이 정리할 수 있습니다.

1. 지식 기반 질의응답 시스템의 한계

   - 초기의 질의응답 시스템은 주로 제한된 도메인의 구조화된 데이터를 기반으로 동작했습니다. 이는 시스템이 다룰 수 있는 주제와 질문의 유형이 한정적이라는 문제가 있었습니다.

   - 사용자의 다양한 정보 요구를 충족시키기 위해서는 보다 광범위한 지식을 활용할 수 있는 시스템이 필요하게 되었습니다.

   - AI모델의 학습 주기나 학습능력에 의해 최신의(실시간성) 정보 제공의 한계

     

2. 비정형 텍스트 데이터의 폭발적 증가

   - 인터넷의 발달과 디지털 기기의 보급으로 웹페이지, 뉴스 기사, 소셜 미디어 게시물 등 비정형 텍스트 데이터가 기하급수적으로 증가하고 있습니다.

   - 이러한 대규모 텍스트 데이터는 방대한 지식을 포함하고 있어, 질의응답 시스템의 지식 베이스로 활용할 수 있는 잠재력이 높습니다.

   - 그러나 비정형 데이터를 효과적으로 처리하고 활용하기 위해서는 기존과는 다른 접근 방식이 필요했습니다.

     

3. 사전 학습된 언어 모델의 발전

   - BERT, GPT 등 사전 학습된 대규모 언어 모델의 등장은 자연어 처리 분야에 큰 변화를 가져왔습니다.

   - 이러한 언어 모델은 방대한 텍스트 데이터로부터 언어의 구조와 의미를 학습하여, 다양한 언어 이해 및 생성 태스크에서 뛰어난 성능을 보여주었습니다.

   - 사전 학습된 언어 모델을 질의응답 시스템에 활용함으로써, 보다 자연스럽고 문맥을 고려한 답변 생성이 가능해졌습니다.

     

4. 실시간 정보 제공에 대한 사용자의 요구 증대

   - 인터넷과 모바일 기기의 발달로 사용자들은 언제 어디서나 필요한 정보를 즉시 얻고자 하는 요구가 커지고 있습니다.

   - 단순히 정보를 검색하는 것을 넘어, 대화형 인터페이스를 통해 원하는 정보를 직관적으로 얻고자 하는 사용자가 늘어났습니다.

   - 이에 따라 사용자의 질문을 이해하고 적절한 답변을 실시간으로 제공할 수 있는 지능형 질의응답 시스템의 필요성이 대두되었습니다.

     

5. 지식 검색과 답변 생성의 통합 필요성

   - 기존의 질의응답 시스템은 지식 검색과 답변 생성을 별도의 단계로 처리하는 경우가 많았습니다. 이로 인해 검색된 정보와 생성된 답변 사이의 정합성이 떨어지는 문제가 발생했습니다.

   - 지식 검색과 답변 생성을 통합적으로 수행할 수 있는 프레임워크의 필요성이 제기되었고, 이는 RAG 아키텍처의 등장으로 이어졌습니다.

     

이러한 배경과 필요성 속에서 RAG는 대규모 비정형 텍스트 데이터를 활용하고, 사전 학습된 언어 모델과 통합 프레임워크를 통해 보다 진보된 형태의 질의응답 시스템을 구현하고자 합니다. RAG는 사용자의 다양한 정보 요구를 만족시키고, 인간과 자연스럽게 상호작용할 수 있는 지능형 대화 시스템의 발전에 기여할 것으로 기대됩니다.



## RAG 기술을 적용한 상용 서비스 사례

RAG 기술을 적용한 상용 서비스는 아직 많지 않지만, 몇몇 대표적인 사례들이 있습니다.

1. Microsoft Bing Search

   - 2023년 2월, Microsoft는 Bing 검색 엔진에 RAG 기술을 적용한 대화형 AI 기능을 추가했습니다.

   - 사용자의 검색 질의에 대해 웹 페이지의 정보를 활용하여 자연어로 응답을 생성합니다.

   - 제공된 응답의 근거가 되는 웹 페이지 링크를 함께 제시합니다.

     

2. Anthropic’s Constitutional AI (CAI)

   - Anthropic사는 RAG 기술을 활용한 대화형 AI 모델인 CAI를 개발했습니다.
   - CAI는 대화 과정에서 외부 지식을 활용하여 사용자의 질문에 답변을 생성합니다.
   - 생성된 응답의 근거가 되는 출처를 명시하여 신뢰성을 높였습니다.

   

3. OpenAI’s WebGPT (in development)

   - OpenAI는 GPT 모델에 RAG 기술을 적용한 WebGPT를 개발 중입니다.
   - WebGPT는 웹 검색을 통해 획득한 지식을 활용하여 사용자의 질의에 대한 응답을 생성할 것으로 예상됩니다.
   - 아직 공개된 서비스는 아니지만, 향후 RAG 기술의 발전 방향을 보여주는 사례로 주목받고 있습니다.

위의 사례들은 RAG 기술의 초기 적용 단계라고 볼 수 있습니다. RAG의 잠재력이 입증됨에 따라 앞으로 더 많은 분야에서 RAG 기반의 서비스들이 등장할 것으로 예상됩니다. 특히 검색 엔진, 가상 어시스턴트, 고객 서비스 등의 분야에서 RAG 기술이 활발히 도입될 것으로 보입니다.

다만 RAG 기술의 상용화를 위해서는

- 지식 베이스의 품질 관리, 

- 프라이버시 보호, 

- 책임 소재 등의 이슈

  기술적 진보와 함께 사회적, 윤리적 문제에 대한 고민이 병행되어야 RAG가 실생활에 안전하게 적용될 수 있을 것입니다.
